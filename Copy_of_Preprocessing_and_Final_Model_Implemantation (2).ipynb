{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjQkVRq-Cmhr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HubuNPyECa2d"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Bike Price Prediction(bikroy.com-NSU)/Data/motorbike_data_final.csv')"
      ],
      "metadata": {
        "id": "Z5m_NcpiRk70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "O9N478iEiSnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "gZO0ueH9ik5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_dims = (10, 10)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.boxplot(x = \"Brand\", y = \"Price\", ax=ax, data=df)"
      ],
      "metadata": {
        "id": "bT63uvWVZu39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to bin years into 5-year intervals\n",
        "def year_group(year):\n",
        "    # Convert to numeric, handling any potential non-numeric values\n",
        "    try:\n",
        "        year = float(year)\n",
        "        # Ensure years are between 1970 and 2024\n",
        "        year = max(1970, min(year, 2024))\n",
        "        return f\"{int((year // 5) * 5)}-{int((year // 5) * 5 + 4)}\"\n",
        "    except (ValueError, TypeError):\n",
        "        return 'Unknown'\n",
        "\n",
        "# Add a new column with 5-year grouped years\n",
        "dfm = df.copy()\n",
        "dfm['Year_Group'] = dfm['Manufactured_year'].apply(year_group)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 7))\n",
        "# Sort the year groups, placing 'Unknown' at the end if it exists\n",
        "sorted_groups = sorted(\n",
        "    dfm['Year_Group'].unique(),\n",
        "    key=lambda x: (x == 'Unknown', x) if x != 'Unknown' else (True, x)\n",
        ")\n",
        "\n",
        "sns.boxplot(x=\"Year_Group\", y=\"Price\", data=dfm, order=sorted_groups)\n",
        "\n",
        "plt.title('Bike Prices by 5-Year Manufactured Year Intervals (1970-2024)', fontsize=16)\n",
        "plt.xlabel('Manufactured Year Group', fontsize=16)\n",
        "plt.ylabel('Price', fontsize=16)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9o_chJPKa59n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFIMHGWeKWwo"
      },
      "outputs": [],
      "source": [
        "class_distribution = df['Brand'].value_counts()\n",
        "print(class_distribution)\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
        "\n",
        "# Plot the class distribution\n",
        "class_distribution.plot(kind='bar')\n",
        "plt.xlabel('Brand')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Class Distribution')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbQ4WmwgoZ_6"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Label encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['Brand','Model','Type']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_enc = LabelEncoder()\n",
        "\n",
        "# List of categorical columns to be encoded\n",
        "cate_to_num = categorical_columns\n",
        "\n",
        "# Apply label encoding to each categorical column and replace the original column with the encoded data\n",
        "for col in cate_to_num:\n",
        "    df[col] = label_enc.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "-TkPUF-4o175"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75tJRPynumPZ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outliner remove"
      ],
      "metadata": {
        "id": "vJ_puPrbn0P_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(figsize=(14,5))\n",
        "plt.title(label='Outliner Distribution',\n",
        "          fontsize=25,\n",
        "          color=\"Red\")"
      ],
      "metadata": {
        "id": "80YsdrALoGTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['Distance(km)'].quantile(0.25)\n",
        "Q3 = df['Distance(km)'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_limit = Q1 - 1.5 * IQR\n",
        "# Ensure that the lower limit is not less than the minimum value in the data\n",
        "lower_limit = max(lower_limit, df['Distance(km)'].min())\n",
        "upper_limit = Q3 + 1.5 * IQR\n",
        "df['Distance(km)'] = np.where(\n",
        "   df['Distance(km)'] > upper_limit,\n",
        "   upper_limit,\n",
        "   np.where(\n",
        "       df['Distance(km)'] < lower_limit,\n",
        "       lower_limit,\n",
        "       df['Distance(km)']\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "yedLrvfenzZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['Price'].quantile(0.25)\n",
        "Q3 = df['Price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_limit = Q1 - 1.5 * IQR\n",
        "lower_limit = max(lower_limit, df['Distance(km)'].min())\n",
        "upper_limit = Q3 + 1.5 * IQR\n",
        "df['Price'] = np.where(\n",
        "   df['Price'] > upper_limit,\n",
        "   upper_limit,\n",
        "   np.where(\n",
        "       df['Price'] < lower_limit,\n",
        "       lower_limit,\n",
        "       df['Price']\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "bl8UXJfao6nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['Engine(cc)'].quantile(0.25)\n",
        "Q3 = df['Engine(cc)'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_limit = Q1 - 1.5 * IQR\n",
        "upper_limit = Q3 + 1.5 * IQR\n",
        "df['Engine(cc)'] = np.where(\n",
        "   df['Engine(cc)'] > upper_limit,\n",
        "   upper_limit,\n",
        "   np.where(\n",
        "       df['Engine(cc)'] < lower_limit,\n",
        "       lower_limit,\n",
        "       df['Engine(cc)']\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "zZOeEZ0zpBT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(figsize=(14,5))\n",
        "plt.title(label='Outliner Distribution',\n",
        "          fontsize=25,\n",
        "          color=\"Red\")"
      ],
      "metadata": {
        "id": "0Ox1Kf_8pGOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwjlMcx7u1T7"
      },
      "outputs": [],
      "source": [
        "selected_features = ['Brand','Manufactured_year','Distance(km)','Engine(cc)']\n",
        "x = df[selected_features]\n",
        "y = df[\"Price\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfleiHUqvSmx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-l5GjVaJq4d"
      },
      "source": [
        "## ML Model/Algorithm Implementations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ5ULj5dIgk9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and Train the Linear Regression Model\n"
      ],
      "metadata": {
        "id": "u5OrOGt6Iy4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb6Qbs0iJ7Q9"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "predictions = lr.predict(x_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "r2 = r2_score(y_test, predictions)*100\n",
        "\n",
        "print('MAE (Mean Absolute Error): %s' %mae)\n",
        "print('MSE (Mean Squared Error): %s' %mse)\n",
        "print('RMSE (Root mean squared error): %s' %rmse)\n",
        "print('R2 score: %s' %r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and Train the Decision Tree Regression Model\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1MneK31JF7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0PCDyPS9LXd"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters and their possible values\n",
        "param_grid = {\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Create the Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "\n",
        "# Fit the grid search to your training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Get the best model\n",
        "best_regressor = grid_search.best_estimator_\n",
        "\n",
        "# Fit the best model to the data\n",
        "best_regressor.fit(x_train, y_train)\n",
        "\n",
        "# Now you can use the best model for predictions\n",
        "y_pred_tr = best_regressor.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, y_pred_tr)\n",
        "mse = mean_squared_error(y_test, y_pred_tr)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred_tr) *100\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ],
      "metadata": {
        "id": "BnSl2LkDJEeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1=best_regressor.predict([[0,2018,20000,150]])\n",
        "y_pred1"
      ],
      "metadata": {
        "id": "nbUgDrYtHkJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and Train the Random Forest Regression Model\n"
      ],
      "metadata": {
        "id": "Is36eDaVJfZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "rf_model.fit(x_train, y_train)\n",
        "y_pred_rf = rf_model.predict(x_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "mse = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred_rf) *100\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ],
      "metadata": {
        "id": "9MBcmYvf0f_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1=rf_model.predict([[0,2018,20000,150]])\n",
        "y_pred1"
      ],
      "metadata": {
        "id": "FncyPDSzrdIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Train the KNeighbors Regression Model"
      ],
      "metadata": {
        "id": "d75l942wszz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a range of values for k to search over\n",
        "param_grid = {'n_neighbors': range(3,20)}\n",
        "\n",
        "# Create a KNN regressor\n",
        "knn_regressor = KNeighborsRegressor()\n",
        "\n",
        "# Create a grid search object\n",
        "grid_search = GridSearchCV(knn_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Get the best value of 'k'\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "print(f\"The best value of k is {best_k}\")\n",
        "\n",
        "# Create a KNN regressor with the best value of 'k' and train it\n",
        "best_knn_regressor = KNeighborsRegressor(n_neighbors=best_k)\n",
        "best_knn_regressor.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions with the best KNN regressor\n",
        "y_pred_knn = best_knn_regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "UJQkOefl3cOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_pred_knn)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_knn)\n",
        "r2 = r2_score(y_test,y_pred_knn)*100\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ],
      "metadata": {
        "id": "iufeJxEq28rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model_filename = \"/content/drive/MyDrive/Bike Price Prediction(bikroy.com-NSU)/Model/knn_model.pkl\"  # Specify the filename for your model\n",
        "# Save the model to a file\n",
        "with open(model_filename, 'wb') as file:\n",
        "    pickle.dump(best_knn_regressor, file)\n"
      ],
      "metadata": {
        "id": "6S9jcwVewLA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1=best_knn_regressor.predict([[0,2017,46000,150]])\n",
        "y_pred1"
      ],
      "metadata": {
        "id": "jq_ezxDIvlS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Train the Gradient Boosting Regression model"
      ],
      "metadata": {
        "id": "l4Vtj1PpvWsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=7, random_state=42)\n",
        "gb_regressor.fit(x_train, y_train)\n",
        "y_pred_gb = gb_regressor.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred_gb)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_gb)\n",
        "r2 = r2_score(y_test,y_pred_gb)*100\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ],
      "metadata": {
        "id": "20uPDHNEvB66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and TrainSVM Regression Model"
      ],
      "metadata": {
        "id": "GzMS6gl-SdtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Scale the features (important for SVR)\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'kernel': ['rbf', 'linear', 'poly'],\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'epsilon': [0.01, 0.1, 0.5, 1]\n",
        "}\n",
        "\n",
        "# Create SVR model\n",
        "svr = SVR()\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=svr,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit Grid Search\n",
        "grid_search.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Get best model\n",
        "best_svr = grid_search.best_estimator_\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svr = best_svr.predict(x_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred_svr)\n",
        "mse = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred_svr) * 100\n",
        "\n",
        "print(\"\\nSupport Vector Regression Results:\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "\n",
        "# Example prediction\n",
        "example_input = [[0, 2018, 20000, 150]]\n",
        "example_input_scaled = scaler.transform(example_input)\n",
        "example_prediction = best_svr.predict(example_input_scaled)\n",
        "print(\"\\nExample Prediction:\")\n",
        "print(f\"Predicted Price for the given input: {example_prediction[0]}\")"
      ],
      "metadata": {
        "id": "apUbz9oUJrtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importance of Features in Decision Tree and Gradient Boosting\n"
      ],
      "metadata": {
        "id": "PX4NifJESUdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Updated feature names (matching the order in x)\n",
        "feature_names = ['Brand', 'Model', 'Manufactured_year', 'Distance(km)', 'Engine(cc)']\n",
        "\n",
        "# Recreate x with all columns\n",
        "selected_features = feature_names\n",
        "x = df[selected_features]\n",
        "\n",
        "# Rerun train-test split with all features\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Retrain Decision Tree with best parameters\n",
        "best_regressor = DecisionTreeRegressor(**best_params, random_state=0)\n",
        "best_regressor.fit(x_train, y_train)\n",
        "\n",
        "# Retrain Gradient Boosting\n",
        "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=7, random_state=42)\n",
        "gb_regressor.fit(x_train, y_train)\n",
        "\n",
        "# Decision Tree Feature Importance\n",
        "print(\"Decision Tree Feature Importance:\")\n",
        "dt_importances = best_regressor.feature_importances_\n",
        "for name, importance in zip(feature_names, dt_importances):\n",
        "    print(f\"{name}: {importance * 100:.2f}%\")\n",
        "\n",
        "# Create a bar plot for Decision Tree feature importances\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Decision Tree - Feature Importances\")\n",
        "plt.bar(feature_names, dt_importances)\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Gradient Boosting Feature Importance\n",
        "print(\"\\nGradient Boosting Feature Importance:\")\n",
        "gb_importances = gb_regressor.feature_importances_\n",
        "for name, importance in zip(feature_names, gb_importances):\n",
        "    print(f\"{name}: {importance * 100:.2f}%\")\n",
        "\n",
        "# Create a bar plot for Gradient Boosting feature importances\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Gradient Boosting - Feature Importances\")\n",
        "plt.bar(feature_names, gb_importances)\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Combine importances into a DataFrame for easy comparison\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Decision Tree Importance': dt_importances*100,\n",
        "    'Gradient Boosting Importance': gb_importances*100\n",
        "})\n",
        "print(\"\\nComparative Feature Importance:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "t8g2cYhINrPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "u5OrOGt6Iy4h",
        "d75l942wszz0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}